# Judge Agent

## Project Intent

A judge agent that evaluates both text and video content and produces four types of analysis:

1. **Origin prediction** — whether the content was generated by a human, AI, or a collaboration of both

   - **Assumption:** Origin is modeled as a three-way prediction: `human`, `ai`, or `ai-assisted`. The `ai-assisted` label captures content that was drafted, structured, cleaned up, or templated with AI involvement but carries meaningful human contribution. Primary detection uses GPTZero API for text content classification, with GPT-4o fallback for low-confidence results or when distinguishing nuanced `ai-assisted` cases.

2. **Virality score** — likelihood the content would perform well socially, based on content-intrinsic signals

   - **Assumption:** Virality scoring uses GPT-4o to reason across four content-intrinsic sub-signals, each scored 0–25 (summing to 100): **emotional_trigger** (does it provoke a strong reaction?), **hook_quality** (does the opening create immediate forward tension?), **novelty** (is it surprising enough to share but familiar enough to understand instantly?), and **compression** (is a large or resonant idea expressed in a tight package?).

3. **Distribution analysis** — which audiences or communities the content would most likely resonate with and why

   - **Assumption:** Distribution analysis uses GPT-4o to reason from content signals — including content type (short-form video, long-form article, tutorial, meme, etc.), topics, domain vocabulary, tone, register, cultural references, and humor style — and maps them to 1–3 most likely audience targets from a fixed taxonomy

4. **Explanation** — a concise rationale for each output the agent produces

   - **Assumption:** Each output includes a summary detailing how the results were determined, along with associated confidence scores for each analysis. This ensures transparency in reasoning and highlights areas where the agent's certainty is higher or lower.

---

<details>
<summary><strong>Instructions for Running App</strong></summary>

### Quick Start (No API Keys Required)

1. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

2. Copy the example env file:

   ```bash
   cp .env.example .env
   ```

3. Run in mock mode (default):

   ```bash
   python main.py
   ```

   The app runs with `USE_MOCK=true` by default in `.env`, which uses simulated responses so you can test without API keys.

### Running with Real API Keys

1. Edit `.env`:

   - Set `USE_MOCK=false`
   - Replace `GPTZERO_API_KEY` with your GPTZero API key
   - Replace `OPENAI_API_KEY` with your OpenAI API key

2. (For video support) Install ffmpeg:

   - macOS: `brew install ffmpeg`
   - Ubuntu: `sudo apt-get install ffmpeg`
   - Windows: Download from https://ffmpeg.org/

3. Run the CLI:
   ```bash
   python main.py
   ```

### Usage

Choose option 1 for text analysis or option 2 for video analysis.

### Supported Input Formats

- **Text**: Plain text string or text file content
- **Video**: Local video files (.mp4, .mov, .avi, etc.)

</details>

---

<details>
<summary><strong>Considerations for Further Improvement</strong></summary>

- **Secure File Processing**

  Handle malicious, oversized, or corrupted files with validation, sanitization, and size limits. Provide clear feedback to users when files are rejected or require preprocessing.

- **Telemetry & Logging**

  Add session-level telemetry and logging to track user interactions, API performance, and error patterns for continuous agent improvement and debugging.

- **AI-Assisted Ratio Breakdown**

  For `ai-assisted` content, provide a granular ratio score showing what percentage of different elements are AI-generated (e.g., 25% deepfake video, 20% synthetic background audio, 30% AI-edited text, 25% human-created content).

- **Distribution-Driven Virality Calculation**

  Calculate virality scores directly from distribution analysis by analyzing the size, engagement rates, and growth potential of identified target audiences.

- **Confidence Calibration**

  Add a second-pass "challenge" prompt where the model critiques its own output and surfaces low-confidence dimensions explicitly.

- **GPTZero SDK Integration**

  Replace raw HTTP calls to GPTZero with the official SDK for better error handling, retry logic, and access to the full response schema including sentence-level AI probability scores.

</details>

---
